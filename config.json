{
    "encoders":
        {"F":
            {"Fin":
                {
                    "nlayers": 4,
                    "channels": [3,16,32,64,128],
                    "kernel_size": [3,3,3,3],
                    "stride": [2,2,2,2],
                    "dilation":[1,1,1,1],
                    "batchnorm":"[True,True,True,True]",
                    "activation":"[ReLU(inplace=True) for t in range(4)]",
                    "dropout":[0.25,0.25,0.25,0.25],
                    "postconv":"BAD"
                },
            "Fxy":
                {
                    "nlayers": 2,
                    "channels": [128,256,512],
                    "kernel_size": [3,3],
                    "stride": [2,2],
                    "dilation":[1,1],
                    "batchnorm":"[True,False]",
                    "activation":"[ReLU(inplace=True) for t in range(1)]+[LeakyReLU(1.0,inplace=True)]",
                    "dropout":[0.25,0.0],
                    "postconv":"BAD"
                },
            "Fyy":
                {
                    "nlayers": 2,
                    "channels": [128,256,512],
                    "kernel_size": [3,3],
                    "stride": [2,2],
                    "dilation":[1,1],
                    "batchnorm":"[True,False]",
                    "activation":"[ReLU(inplace=True) for t in range(1)]+[LeakyReLU(1.0,inplace=True)]",
                    "dropout":[0.25,0.0],
                    "postconv":"BAD"
                }
            }
        },
    "decoders":
        {"G":
            {"Gxx":
                {
                    "nlayers": 6,
                    "channels": [512,256,128,64,32,16],
                    "kernel_size": [3,3,3,3,3,3],
                    "stride": [2,2,2,2,2,2],
                    "dilation":[1,1,1,1,1,1],
                    "batchnorm":"[True,True,True,True,True,False]",
                    "activation":"[ReLU(inplace=True) for t in range(6)]+[LeakyReLU(1.0,inplace=True)]",
                    "dropout":[0.25,0.25,0.25,0.25,0.25,0.0],
                    "postconv":"BAD"
                },
            "Gyy":
                {
                    "nlayers": 6,
                    "channels": [512,256,128,64,32,16],
                    "kernel_size": [3,3,3,3,3,3],
                    "stride": [2,2,2,2,2,2],
                    "dilation":[1,1,1,1,1,1],
                    "batchnorm":"[True,True,True,True,True,False]",
                    "activation":"[ReLU(inplace=True) for t in range(6)]+[LeakyReLU(1.0,inplace=True)]",
                    "dropout":[0.25,0.25,0.25,0.25,0.25,0.0],
                    "postconv":"BAD"
                }
            }
        }
}